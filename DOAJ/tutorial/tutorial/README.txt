Este repositorio utiliza las t√©cnicas de web crawler y web scraping  bajo la arquitectura de la libreria scrapy para
python 3.

Para inicializar su funcionamiento, primero se realiza una copia del respositorio git, se accede a la carpeta spiders desde
la consola y se ejecuta los siguientes comandos:


cd Merlot
cd tutorial
scrapy crawl web_scraping -t csv

La salida salida es el archivo web_scraping_items.csv